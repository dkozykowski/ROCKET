{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a767542",
   "metadata": {},
   "source": [
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "211ade71",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(reticulate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa3b5859",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn <- import(\"sklearn\")\n",
    "datasets <- import(\"sktime.datasets\")\n",
    "np <- import(\"numpy\")\n",
    "utils <- import(\"sktime.utils.validation.panel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f340a6",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f856735",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d747dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_head <- datasets$load_basic_motions(split=\"train\", return_X_y=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "65d32249",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train <- arrow_head[[1]]\n",
    "y_train <- arrow_head[[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad08f5e",
   "metadata": {},
   "source": [
    "### Truncate some of the time series in order to complicate the problem\n",
    "\n",
    "- 33.(3)% of sequences left at 50% length\n",
    "- 33.(3)% of sequences truncated to 40% length\n",
    "- 33.(3)% of sequences truncated to 30% length\n",
    "\n",
    "#### In order to ensure that all classes are treated equally stratyfikacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "678656ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncate_time_serie <- function(time_serie, coefficient) {\n",
    "    time_serie_length = length(time_serie[[1]][[1]])  # number of observations in each time serie\n",
    "    time_serie_dims = length(time_serie)              # number of dimensions of each time serie\n",
    "    \n",
    "    number_of_samples = ceiling(coefficient * time_series_length / 100) #- 2 # upper and lower bound must be added manually\n",
    "    \n",
    "    mask = sort(sample(0 : (time_series_length - 1), number_of_samples)) \n",
    "\n",
    "    for (j in 1 : time_series_dims)\n",
    "        time_serie[[j]][[1]] = time_serie[[j]][[1]][mask]\n",
    "    \n",
    "    return(time_serie)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "30312130",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "original_length = length(x_train[1,][[1]][[1]]) # save the original time series length\n",
    "\n",
    "for (class in unique(y_train)) {\n",
    "    indexes = which(y_train == class)\n",
    "    \n",
    "    for (i in 1 : length(indexes)) {\n",
    "        if (i <= length(indexes) / 3) {\n",
    "            x_train[indexes[i],] = truncate_time_serie(x_train[indexes[i],], 100)\n",
    "        }\n",
    "        else if (i <= 2 * length(indexes) / 3) {\n",
    "            x_train[indexes[i],] = truncate_time_serie(x_train[indexes[i],], 90)\n",
    "        }\n",
    "        else {\n",
    "            x_train[indexes[i],] = truncate_time_serie(x_train[indexes[i],], 80)\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c6e465",
   "metadata": {},
   "source": [
    "# ROCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f54b0f9",
   "metadata": {},
   "source": [
    "### Standarize time series length by repeating observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3ea0e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_length <- function(x, expected_length) {\n",
    "    current_length = length(x)\n",
    "    \n",
    "    if (current_length != expected_length) {\n",
    "        x_args = strtoi(stringr::str_trim(names(x)), 10)\n",
    "        y_args = as.vector(x)\n",
    "        return(approx(x_args, y_args, 0:(expected_length - 1))$y)\n",
    "    }\n",
    "    \n",
    "    return(x)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f0609",
   "metadata": {},
   "source": [
    "### Generate kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077a58bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a02431",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8cf09e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16da8380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "45539593",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_head <- datasets$load_basic_motions(split=\"train\", return_X_y=TRUE)\n",
    "x_train <- arrow_head[[1]]\n",
    "y_train <- arrow_head[[2]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec8b153",
   "metadata": {},
   "source": [
    "### Generate kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3106178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(5)\n",
    "np$random$seed(as.integer(5))\n",
    "num_kernels = 10000 # default value\n",
    "\n",
    "temp_x_train = utils$check_X(x_train, coerce_to_numpy=TRUE)\n",
    "\n",
    "num_columns = dim(temp_x_train)[2]\n",
    "num_timepoints = dim(temp_x_train)[3]\n",
    "\n",
    "lengths = array(as.integer(sample(c(7, 9, 11), num_kernels, replace = TRUE)))\n",
    "\n",
    "limit = pmin(num_columns, lengths)\n",
    "\n",
    "num_channel_indices = as.integer(2 ** np$random$uniform(0, log2(limit + 1)))\n",
    "\n",
    "channel_indices = as.integer(rep(0, sum(num_channel_indices)))\n",
    "\n",
    "weights = as.double(rep(0, sum(lengths * num_channel_indices)))\n",
    "\n",
    "biases = array(as.double(rep(0, num_kernels)))\n",
    "dilations = array(as.integer(rep(0, num_kernels)))\n",
    "paddings = array(as.integer(rep(0, num_kernels)))\n",
    "\n",
    "a1 = 1  # for weights\n",
    "a2 = 1  # for channel_indices\n",
    "\n",
    "for (i in 1 : num_kernels) {\n",
    "    temp_length = lengths[i]\n",
    "    temp_num_channel_indices = num_channel_indices[i]\n",
    "\n",
    "    temp_weights = as.double(np$random$normal(0, 1, temp_num_channel_indices * temp_length))\n",
    "\n",
    "    b1 = a1 + (temp_num_channel_indices * temp_length) - 1 \n",
    "    b2 = a2 + temp_num_channel_indices - 1\n",
    "\n",
    "    a3 = 1 # for weights (per channel)\n",
    "    for (j in 1 : temp_num_channel_indices) {\n",
    "        b3 = a3 + temp_length - 1\n",
    "        temp_weights[a3 : b3] = temp_weights[a3 : b3] - mean(temp_weights[a3 : b3])\n",
    "        a3 = b3 + 1\n",
    "    }\n",
    "        \n",
    "\n",
    "    weights[a1 : b1] = temp_weights\n",
    "\n",
    "    channel_indices[a2 : b2] = sample(0 : (num_columns - 1), temp_num_channel_indices)\n",
    "\n",
    "    biases[i] = np$random$uniform(-1, 1)\n",
    "\n",
    "    dilation = 2 ** np$random$uniform(0, log2((num_timepoints - 1) / (temp_length - 1)))\n",
    "    dilation = as.integer(dilation)\n",
    "    dilations[i] = dilation\n",
    "\n",
    "    if (sample(0 : 1, 1) == 1)\n",
    "        paddings[i] = as.integer(((temp_length - 1) * dilation) / 2)\n",
    "    else paddings[i] = 0\n",
    "\n",
    "    a1 = b1 + 1\n",
    "    a2 = b2 + 1\n",
    "} \n",
    "\n",
    "channel_indices = channel_indices + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f954efd6",
   "metadata": {},
   "source": [
    "### Transform x_train with created kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41a1b39",
   "metadata": {},
   "source": [
    "#### Transform x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dc059db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_kernel_multivariate <- function(X, \n",
    "                                      weights, \n",
    "                                      length, \n",
    "                                      bias, \n",
    "                                      dilation, \n",
    "                                      padding, \n",
    "                                      num_channel_indices, \n",
    "                                      channel_indices) {\n",
    "    \n",
    "    num_columns = dim(X)[1]\n",
    "    num_timepoints = dim(X)[2]\n",
    "\n",
    "    output_length = (num_timepoints + (2 * padding)) - ((length - 1) * dilation)\n",
    "\n",
    "    temp_ppv = 0\n",
    "    temp_max = -Inf\n",
    "\n",
    "    end = (num_timepoints + padding) - ((length - 1) * dilation) - 1\n",
    "    \n",
    "    for (i in (-padding + 1) : end) \n",
    "    {\n",
    "        temp_sum = bias\n",
    "\n",
    "        index = i\n",
    "\n",
    "        for (j in 1 : length) {\n",
    "            if (index > 0 && index <= num_timepoints) {\n",
    "                for (k in 1 : num_channel_indices) {\n",
    "                    temp_sum = temp_sum + weights[k, j] * X[channel_indices[k], index]\n",
    "                }\n",
    "                    \n",
    "            }\n",
    "            index = index + dilation\n",
    "        }\n",
    "            \n",
    "        if (temp_sum > temp_max)\n",
    "            temp_max = temp_sum\n",
    "\n",
    "        if (temp_sum > 0)\n",
    "            temp_ppv = temp_ppv + 1 \n",
    "    }\n",
    "    return(c(as.double(temp_ppv / output_length), as.double(temp_max)))\n",
    "}\n",
    "\n",
    "\n",
    "apply_kernel_univariate <- function(X, weights, length, bias, dilation, padding) {\n",
    "    num_timepoints = length(X)\n",
    "\n",
    "    output_length = (num_timepoints + (2 * padding)) - ((length - 1) * dilation)\n",
    "\n",
    "    temp_ppv = 0\n",
    "    temp_max = -Inf\n",
    "\n",
    "    end = (num_timepoints + padding) - ((length - 1) * dilation)\n",
    "\n",
    "    for (i in (-padding + 1) : end) \n",
    "    {\n",
    "        temp_sum = bias\n",
    "\n",
    "        index = i\n",
    "\n",
    "        for (j in 1 : length) {\n",
    "            if (index > 0 && index <= num_timepoints)\n",
    "                temp_sum = temp_sum + weights[j] * X[index]\n",
    "\n",
    "            index = index + dilation\n",
    "\n",
    "        }\n",
    "            \n",
    "        if (temp_sum > temp_max)\n",
    "            temp_max = temp_sum\n",
    "\n",
    "        if (temp_sum > 0)\n",
    "            temp_ppv = temp_ppv + 1\n",
    "    }\n",
    "    return(c(as.double(temp_ppv / output_length), as.double(temp_max)))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f570a53d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "apply_kernels <- function(x) {\n",
    "    x = utils$check_X(x, coerce_to_numpy=TRUE)\n",
    "    \n",
    "    num_instances = dim(x)[1]\n",
    "    num_columns = dim(x)[2]\n",
    "    \n",
    "    for(i in 1 : num_instances) {\n",
    "        for (o in 1 : num_columns) {\n",
    "            x[i,o,] = (x[i,o,] - mean(x[i,o,])) / sd(x[i,o,]) + 1e-8 \n",
    "        }\n",
    "    }\n",
    "\n",
    "    num_kernels = length(lengths)\n",
    "\n",
    "    new_x = matrix(0, num_instances, num_kernels * 2)  # 2 features per kernel\n",
    "\n",
    "    for (i in 1 : num_instances) {\n",
    "        a1 = 1  # for weights\n",
    "        a2 = 1  # for channel_indices\n",
    "        a3 = 1  # for features\n",
    "\n",
    "        for (j in 1 : num_kernels)\n",
    "        {\n",
    "            b1 = a1 + num_channel_indices[j] * lengths[j] - 1\n",
    "            b2 = a2 + num_channel_indices[j] - 1\n",
    "            b3 = a3 + 2 - 1\n",
    "\n",
    "            if (num_channel_indices[j] == 1)\n",
    "            {\n",
    "\n",
    "                temp_result = apply_kernel_univariate(\n",
    "                    x[i, channel_indices[a2],],\n",
    "                    weights[a1:b1],\n",
    "                    lengths[j],\n",
    "                    biases[j],\n",
    "                    dilations[j],\n",
    "                    paddings[j]\n",
    "                ) \n",
    "                new_x[i, a3] = temp_result[1]\n",
    "                new_x[i, a3 + 1] = temp_result[2]\n",
    "            }\n",
    "            else\n",
    "            {\n",
    "                temp_weights = matrix(weights[a1 : b1], num_channel_indices[j], lengths[j])\n",
    "\n",
    "                temp_result = apply_kernel_multivariate(\n",
    "                    x[i,,],\n",
    "                    temp_weights,\n",
    "                    lengths[j],\n",
    "                    biases[j],\n",
    "                    dilations[j],\n",
    "                    paddings[j],\n",
    "                    num_channel_indices[j],\n",
    "                    channel_indices[a2:b2]\n",
    "                )\n",
    "                new_x[i, a3] = temp_result[1]\n",
    "                new_x[i, a3 + 1] = temp_result[2]\n",
    "            }\n",
    "\n",
    "            a1 = b1 + 1\n",
    "            a2 = b2 + 1\n",
    "            a3 = b3 + 1       \n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return(as.data.frame(new_x))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "dc11d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = apply_kernels(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "775995e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifierCV(alphas=array([1.00000000e-03, 4.64158883e-03, 2.15443469e-02, 1.00000000e-01,\n",
       "       4.64158883e-01, 2.15443469e+00, 1.00000000e+01, 4.64158883e+01,\n",
       "       2.15443469e+02, 1.00000000e+03]),\n",
       "                  normalize=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "linear_model <- import(\"sklearn.linear_model\")\n",
    "\n",
    "classifier = linear_model$RidgeClassifierCV(alphas=pracma::logspace(-3, 3, 10), normalize=TRUE)\n",
    "classifier$fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "cee34841",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow_head <- datasets$load_basic_motions(split=\"test\", return_X_y=TRUE)\n",
    "x_test <- arrow_head[[1]]\n",
    "y_test <- arrow_head[[2]]\n",
    "\n",
    "x_test = apply_kernels(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0465aa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "1"
      ],
      "text/latex": [
       "1"
      ],
      "text/markdown": [
       "1"
      ],
      "text/plain": [
       "[1] 1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier$score(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
